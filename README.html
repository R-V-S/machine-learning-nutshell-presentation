<!doctype html>
<html>
  <head>
    <title>Machine Learning: In a Nutshell</title>
    <style>
      body {
        text-align: center;
        font-family: 'Playfair Display', serif;
      }
      slide {
        height: 97vh;
        justify-content: center;
        text-align: center;
        display: block;
      }
      h1, h2 {
        letter-spacing: 0.33px;
        color: hsl(0, 0%, 26%);
        transform: translateY(-50%);
        font-size: 4vw;
        clear: both;
        font-weight: 900;
      }
      h1 {
      }
      h2 {
        font-size: 3vw;
      }
      img {
        display: inline-block;
      }
      p, li {
        color: hsl(0, 0%, 35%);
        font-weight: normal;
        font-size: 2vw;
      }
      ul, ol, p {
        padding: 0 10vw;
      }
      li {
        margin-bottom: 3vh;
        text-align: left;
      }
      
    </style>
    <link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700,700i,900" rel="stylesheet" />
  </head>
  <body>
    <slide style="display: flex; align-items: center;">
      <h1>Machine Learning: In a Nutshell</h1>
    </slide>

    <slide>
      <h2>What is it?</h2>
      <p>Goal-oriented software that becomes more successful at achieving its goals as it processes more data.</p>
      <img src="recipes.png" />
    </slide>
  
    <slide>
      <h2>Why bother using machine learning?</h2>
      <ul>
        <li><strong>Problem scalability</strong>: There's a tipping point at which abstractions designed to simplify complex problems 
          fail to perform well, or exceed maintenance costs.</li>
        <li><strong>Data-based validation</strong>: Manual software solutions bake the assumptions of the software engineers into the 
        solution. Checking solutions against a data set forces solutions to be robust. <em>Caveat: ML software can form its own biases, 
          if they exist in the data.</em></li>
      </ul>
      <img src="tay-screenshot.png" style="height: 30vh;" />
    </slide>

    <slide>
      <h2>When to use it?</h2>
      <ol>
        <li>You have data.</li>
        <li>You want to draw conclusions from that data.</li>
        <li>A highly abstracted and opinionated solution won't give you the conclusions you want.</li>
      </ol>
      <p><em>Example: Try diagramming a solution to a problem that's based on analyzing data. As you explore 
        scenarios, does the diagram necessarily become so complex that it becomes hard to organize, or does it become overwhelming?</em></p>
    </slide>

    <slide>
      <h2>When <em>not</em> to use it?</h2>
      <ul>
        <li>A simplified system or algorithm will do the job reasonably well – there's an inherent degree of unpredictability 
          to ML software. Many of the costs involved in new ML software are "unknown unknowns" at a project's outset.</li>
        <li>You want to predict the future within an open system – if there are variables that can't be adjusted for, or if 
          there's an effective degree of randomness to the data, accuracy will be low, and could even degrade as the data set grows.</li>
        <li>You want to use data without understanding it – although human time is expensive, humans are also extremely effective. 
          Most data sets can be utilized in a way that doesn't require much (if any) ML.
        </li>
      </ul>
    </slide>

    <slide>
      <ul>
        <li>There needs to be a rationale or justification behind decisions that are made – most mathematical algorithms 
          are opaque and either don't have or don't expose any underlying, abstract logic.</li>
        <li>The system is susceptible to "observer effect" – if your system can react to your software, and if that reaction
          is undesirable, you may find that your software is chasing its own tail. 
          <em>Example: anomaly detection in security applications.</em></li>
      </ul>
    </slide>

    <slide>
      <h2>Things that Sound Magical But Aren't</h2>
      <ul>
        <li><strong>Machine Learning</strong>: Statistics, supercharged.</li>
        <li><strong>Deep Learning</strong>: ML applications where the software is designed to build its own abstractions.</li>
        <li><strong>Neural Networks</strong>: Polynomial equations that use differential calculus to fit curves. 
          Nothing to do with the brain, really. </li>
      </ul>
    </slide>

    <slide>
      <img src="machine_learning.png" style="height: 70vh;" />  
    </slide>

    <slide>
      <h2>Types of Approaches</h2>
      <ul>
        <li><strong>Supervised Learning</strong>: Humans prep the data by labelling/categorizing items beforehand, and then feed the software. 
          High human cost, low machine cost.</li>
        <li><strong>Unserpervised Learning</strong>: Humans feed the data to the software with no pre-labelling.</li>
      </ul>
    </slide>

    <slide>
      <h2>Types of Problems</h2>
      <ul>
        <li><strong>Sequence Prediction</strong>: Text, speech, video, audio, and temporal data. Anything that must be represented 
          as an ordered list to be coherent. <em>Example: sentence auto-complete.</em></li>
        <li><strong>Classification</strong>: Identify items as belonging to a pre-defined group (i.e. who/what/where is this?). 
          <em>Examples: image subject identification, handwriting image-to-text.</em></li>
        <li><strong>Regression</strong>: Map inputs to a quantity or numerical value (i.e. how much? how many?). 
          <em>Examples: price forecasting, real estate value estimation.</em></li>
        <li><strong>Clustering</strong>: Group items based on inferred relationship(s) between them. 
          <em>Examples: social network analysis, server network anomaly detection, pizza delivery.</em></li>
      </ul>
    </slide>

    <slide>
      <h2><em>Fin.</em></h2>
    </slide>
  </body>
</html>